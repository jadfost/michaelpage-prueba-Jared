# azure-pipelines.yml
# Pipeline multi-stage: Terraform IaC en GCP con aprobaciones
# + stage de federaciÃ³n BigLake (Delta Lake en ADLS Gen2 Azure â†’ BigQuery Omni)
# Ramas: dev -> qa -> prod

trigger:
  branches:
    include:
      - dev
      - qa
      - prod

variables:
  - group: gcp-credentials        # GCP_PROJECT_ID, GCP_SA_KEY_JSON, ADLS_ACCESS_KEY
  - name: TF_VERSION
    value: "1.7.5"
  - name: TF_WORKING_DIR
    value: "$(System.DefaultWorkingDirectory)/iac"
  - name: TF_PREFIX
    value: "mp"
  - name: TF_REGION
    value: "us-central1"
  - name: GCS_BUCKET
    value: "raw-dev-michaelpage-prueba"
  - name: DELTA_PATH
    value: "delta/transactions"
  - name: BQ_DATASET
    value: "dw_dev"
  - name: BQ_TABLE
    value: "transactions_federated"
  - name: ADLS_ACCOUNT_NAME
    value: "jaredpruebadelta"
  - name: ADLS_CONTAINER
    value: "datalake"
  - name: ADLS_DELTA_PATH
    value: "transactions_uniform"
  - name: BQ_AZURE_CONNECTION
    value: "348306483800.azure-eastus2.adls-biglake-conn"

stages:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DEV
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - stage: plan_dev
    displayName: "ğŸ” Plan â€“ DEV"
    condition: eq(variables['Build.SourceBranch'], 'refs/heads/dev')
    jobs:
      - job: terraform_plan_dev
        displayName: "Terraform Plan DEV"
        pool: Default
        steps:
          - template: templates/tf-setup.yml
          - powershell: |
              Set-Location "$(TF_WORKING_DIR)"
              terraform workspace select dev
              if ($LASTEXITCODE -ne 0) { terraform workspace new dev }
              $project = "$(GCP_PROJECT_ID)"
              $prefix  = "$(TF_PREFIX)"
              $region  = "$(TF_REGION)"
              terraform plan -var "project_id=$project" -var "prefix=$prefix" -var "region=$region" -target module.dev -out tfplan_dev
            displayName: "terraform plan (dev)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
          - publish: $(TF_WORKING_DIR)/tfplan_dev
            artifact: tfplan_dev

  - stage: apply_dev
    displayName: "ğŸš€ Apply â€“ DEV"
    dependsOn: plan_dev
    condition: succeeded()
    jobs:
      - deployment: terraform_apply_dev
        displayName: "Terraform Apply DEV"
        environment: "dev"
        pool: Default
        strategy:
          runOnce:
            deploy:
              steps:
                - template: templates/tf-setup.yml
                # Descargar el plan generado en plan_dev para garantizar que
                # se aplica exactamente lo que fue revisado/aprobado (no se recalcula).
                - download: current
                  artifact: tfplan_dev
                  displayName: "Descargar artifact tfplan_dev"
                - powershell: |
                    # Copiar el plan al directorio de trabajo de Terraform
                    Copy-Item "$(Pipeline.Workspace)/tfplan_dev/tfplan_dev" "$(TF_WORKING_DIR)/tfplan_dev"
                    Set-Location "$(TF_WORKING_DIR)"
                    terraform workspace select dev
                    terraform apply -auto-approve tfplan_dev
                  displayName: "terraform apply (dev)"
                  env:
                    GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # BIGLAKE SETUP â€” escribe Delta en ADLS Gen2 y crea tabla externa
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - stage: biglake_setup
    displayName: "ğŸ”— BigLake â€“ Delta Lake ADLS Gen2 â†’ BigQuery Omni"
    dependsOn: apply_dev
    condition: succeeded()
    jobs:
      - job: setup_biglake
        displayName: "Escribir Delta â†’ ADLS Gen2 â†’ BigLake"
        pool: Default
        steps:

          - powershell: |
              $base64 = $env:GCP_SA_KEY_JSON
              $bytes  = [Convert]::FromBase64String($base64.Trim())
              $json   = [System.Text.Encoding]::UTF8.GetString($bytes)
              $path   = "$env:TEMP\sa_key.json"
              [System.IO.File]::WriteAllText($path, $json, (New-Object System.Text.UTF8Encoding $false))
              Write-Host "Credenciales GCP escritas en $path"
              echo "##vso[task.setvariable variable=GOOGLE_APPLICATION_CREDENTIALS]$path"
            displayName: "Configurar credenciales GCP"
            env:
              GCP_SA_KEY_JSON: $(GCP_SA_KEY_JSON)

          - powershell: |
              $pyDir  = "C:\agent\_work\python310"
              $pyZip  = "$env:TEMP\python-embed.zip"
              $getpip = "$env:TEMP\get-pip.py"

              if (-not (Test-Path "$pyDir\python.exe")) {
                Write-Host "Descargando Python embeddable..."
                Invoke-WebRequest "https://www.python.org/ftp/python/3.10.9/python-3.10.9-embed-amd64.zip" -OutFile $pyZip
                Expand-Archive $pyZip -DestinationPath $pyDir -Force
                $pthFile = Get-ChildItem $pyDir -Filter "*._pth" | Select-Object -First 1
                (Get-Content $pthFile.FullName) -replace "#import site", "import site" | Set-Content $pthFile.FullName
                Invoke-WebRequest "https://bootstrap.pypa.io/get-pip.py" -OutFile $getpip
                & "$pyDir\python.exe" $getpip --quiet
              }

              Write-Host "Instalando dependencias con soporte Azure..."
              & "$pyDir\python.exe" -m pip install `
                  "deltalake[azure]==0.17.4" `
                  pyarrow `
                  google-cloud-bigquery `
                  google-cloud-storage `
                  azure-storage-blob `
                  pandas-gbq `
                  --quiet

              Write-Host "Dependencias instaladas"
              echo "##vso[task.setvariable variable=PYTHON_EXE]$pyDir\python.exe"
            displayName: "Instalar Python y dependencias (con soporte Azure)"

          - powershell: |
              $env:GOOGLE_APPLICATION_CREDENTIALS = "$env:TEMP\sa_key.json"
              $env:GCS_BUCKET        = "$(GCS_BUCKET)"
              $env:GCS_DELTA_PATH    = "$(DELTA_PATH)"
              $env:ADLS_ACCOUNT_NAME = "$(ADLS_ACCOUNT_NAME)"
              $env:ADLS_CONTAINER    = "$(ADLS_CONTAINER)"
              $env:ADLS_DELTA_PATH   = "$(ADLS_DELTA_PATH)"
              $env:ADLS_ACCESS_KEY   = $env:ADLS_ACCESS_KEY_SECRET

              Write-Host "Paso 1: Escribiendo Delta Lake en ADLS Gen2: $(ADLS_ACCOUNT_NAME)/$(ADLS_CONTAINER)/$(ADLS_DELTA_PATH)"
              & "$(PYTHON_EXE)" "$(System.DefaultWorkingDirectory)/src/jobs/create_delta_data.py"
              if ($LASTEXITCODE -ne 0) { exit 1 }
              Write-Host "Tabla Delta escrita exitosamente en ADLS Gen2"
            displayName: "Paso 1 â€” Escribir Delta Lake en ADLS Gen2 (Azure)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
              ADLS_ACCESS_KEY_SECRET: $(ADLS_ACCESS_KEY)

          - powershell: |
              $env:GOOGLE_APPLICATION_CREDENTIALS = "$env:TEMP\sa_key.json"
              $env:BQ_PROJECT       = "$(GCP_PROJECT_ID)"
              $env:BQ_DATASET       = "$(BQ_DATASET)"
              $env:BQ_TABLE         = "$(BQ_TABLE)"
              $env:BQ_CONNECTION    = "$(BQ_AZURE_CONNECTION)"
              $env:ADLS_URI         = "abfss://$(ADLS_CONTAINER)@$(ADLS_ACCOUNT_NAME).dfs.core.windows.net/$(ADLS_DELTA_PATH)"
              $env:ADLS_ACCOUNT_NAME = "$(ADLS_ACCOUNT_NAME)"
              $env:ADLS_ACCESS_KEY  = $env:ADLS_ACCESS_KEY_VAR

              Write-Host "Paso 2: Creando dw_dev_omni.transactions_federated en BigQuery Omni (azure-eastus2)..."
              Write-Host "  Dataset destino: dw_dev_omni (azure-eastus2) â€” solo tabla externa DELTA_LAKE"
              Write-Host "  Conexion: $env:BQ_CONNECTION"
              Write-Host "  ADLS URI: $env:ADLS_URI"

              & "$(PYTHON_EXE)" "$(System.DefaultWorkingDirectory)/src/jobs/create_biglake_omni.py"
              if ($LASTEXITCODE -ne 0) { exit 1 }
              Write-Host "Tabla externa DELTA_LAKE creada en dw_dev_omni.transactions_federated (azure-eastus2)"
            displayName: "Paso 2 â€” Crear tabla externa Omni (DELTA_LAKE) en dw_dev_omni (azure-eastus2)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
              ADLS_ACCESS_KEY_VAR: $(ADLS_ACCESS_KEY)

          - powershell: |
              $env:GOOGLE_APPLICATION_CREDENTIALS = "$env:TEMP\sa_key.json"
              $env:ADLS_ACCESS_KEY = $env:ADLS_ACCESS_KEY_SECRET
              Write-Host "Paso 3: Python ETL Bridge â€” Delta Lake ADLS Gen2 â†’ BigQuery + MERGE"
              Write-Host "  4.1+4.2 - ADLS Gen2 (deltalake) â†’ dw_dev.transactions_staging (BigQuery US)"
              Write-Host "  4.3     - customers + final_table (CREATE IF NOT EXISTS en US)"
              Write-Host "  4.4     - MERGE transactions_staging + customers â†’ final_table"
              Write-Host "  4.5     - Labels Dataplex aplicados"
              & "$(PYTHON_EXE)" "$(System.DefaultWorkingDirectory)/src/jobs/run_merge.py" `
                --project        "$(GCP_PROJECT_ID)"    `
                --dataset        "$(BQ_DATASET)"        `
                --env            "dev"                  `
                --adls-account   "$(ADLS_ACCOUNT_NAME)" `
                --adls-container "$(ADLS_CONTAINER)"    `
                --adls-path      "$(ADLS_DELTA_PATH)"
              if ($LASTEXITCODE -ne 0) { exit 1 }
              Write-Host "ETL Bridge y MERGE ejecutados exitosamente en $(BQ_DATASET)"
            displayName: "Paso 3 â€” ETL Bridge Delta Lake â†’ BigQuery + MERGE en dw_dev (US)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
              ADLS_ACCESS_KEY_SECRET: $(ADLS_ACCESS_KEY)

  # QA
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - stage: plan_qa
    displayName: "ğŸ” Plan â€“ QA"
    dependsOn: biglake_setup
    condition: succeeded()
    jobs:
      - job: terraform_plan_qa
        displayName: "Terraform Plan QA"
        pool: Default
        steps:
          - template: templates/tf-setup.yml
          - powershell: |
              Set-Location "$(TF_WORKING_DIR)"
              terraform workspace select qa
              if ($LASTEXITCODE -ne 0) { terraform workspace new qa }
              $project = "$(GCP_PROJECT_ID)"
              $prefix  = "$(TF_PREFIX)"
              $region  = "$(TF_REGION)"
              terraform plan -var "project_id=$project" -var "prefix=$prefix" -var "region=$region" -target module.qa -out tfplan_qa
            displayName: "terraform plan (qa)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
          - publish: $(TF_WORKING_DIR)/tfplan_qa
            artifact: tfplan_qa

  - stage: apply_qa
    displayName: "ğŸš€ Apply â€“ QA  [requiere aprobaciÃ³n: Tech Lead]"
    dependsOn: plan_qa
    condition: succeeded()
    jobs:
      - deployment: terraform_apply_qa
        displayName: "Terraform Apply QA"
        environment: "qa"
        pool: Default
        strategy:
          runOnce:
            deploy:
              steps:
                - template: templates/tf-setup.yml
                - download: current
                  artifact: tfplan_qa
                  displayName: "Descargar artifact tfplan_qa"
                - powershell: |
                    Copy-Item "$(Pipeline.Workspace)/tfplan_qa/tfplan_qa" "$(TF_WORKING_DIR)/tfplan_qa"
                    Set-Location "$(TF_WORKING_DIR)"
                    terraform workspace select qa
                    terraform apply -auto-approve tfplan_qa
                  displayName: "terraform apply (qa)"
                  env:
                    GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # PROD
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - stage: plan_prod
    displayName: "ğŸ” Plan â€“ PROD"
    dependsOn: apply_qa
    condition: succeeded()
    jobs:
      - job: terraform_plan_prod
        displayName: "Terraform Plan PROD"
        pool: Default
        steps:
          - template: templates/tf-setup.yml
          - powershell: |
              Set-Location "$(TF_WORKING_DIR)"
              terraform workspace select prod
              if ($LASTEXITCODE -ne 0) { terraform workspace new prod }
              $project = "$(GCP_PROJECT_ID)"
              $prefix  = "$(TF_PREFIX)"
              $region  = "$(TF_REGION)"
              terraform plan -var "project_id=$project" -var "prefix=$prefix" -var "region=$region" -target module.prod -out tfplan_prod
            displayName: "terraform plan (prod)"
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)
          - publish: $(TF_WORKING_DIR)/tfplan_prod
            artifact: tfplan_prod

  - stage: apply_prod
    displayName: "ğŸš€ Apply â€“ PROD  [requiere aprobaciÃ³n: Arquitecto/Owner]"
    dependsOn: plan_prod
    condition: succeeded()
    jobs:
      - deployment: terraform_apply_prod
        displayName: "Terraform Apply PROD"
        environment: "prod"
        pool: Default
        strategy:
          runOnce:
            deploy:
              steps:
                - template: templates/tf-setup.yml
                - download: current
                  artifact: tfplan_prod
                  displayName: "Descargar artifact tfplan_prod"
                - powershell: |
                    Copy-Item "$(Pipeline.Workspace)/tfplan_prod/tfplan_prod" "$(TF_WORKING_DIR)/tfplan_prod"
                    Set-Location "$(TF_WORKING_DIR)"
                    terraform workspace select prod
                    terraform apply -auto-approve tfplan_prod
                  displayName: "terraform apply (prod)"
                  env:
                    GOOGLE_APPLICATION_CREDENTIALS: $(GOOGLE_APPLICATION_CREDENTIALS)